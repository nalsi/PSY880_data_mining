getTwitterOAuth
registerTwitterOAuth()
setup_twitter_oauth()
setup_twitter_oauth(list(appname = "altmetrics"))
View(data)
sum(data$answer_count)
?stack_search
knitr::opts_chunk$set(echo = TRUE)
library(stackr) #StackOverflow
library(twitteR) #Twitter
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 20, num_pages = 500)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 10, num_pages = 1500)
View(data_ggplot2)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 20)
View(data_ggplot2)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 500, pagesize = 20)
View(data_ggplot2)
View(data)
dataset <- data.frame(rep(NA, 47))
View(dataset)
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 47))
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 47))
for (i in 1:2) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 500, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
View(dataset)
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 47))
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 500, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
authorize()
??authorize
install.packages("RGA")
library(RGA)
authroize()
authorize()
list_profiles()
View(dataset)
write.csv(dataset, "sof.csv", row.names = F)
Sys.setenv(STACK_EXCHANGE_KEY = "xIBTCksECxreUfRnWIbXgQ((")
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 500, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 47))
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 500, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
for (i in 751:800) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 500, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
View(dataset)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 20)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 47))
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 18))
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)[,1:18]
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 20)
View(data_ggplot2)
data_ggplot21 <- stack_search(tagged = c("ggplot2"), page = 2, pagesize = 20)
View(data_ggplot21)
colnames(data_ggplot2)
colnames(data_ggplot21)
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 14))
for (i in 1:750) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)[,1:14]
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
}
}
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 20)[,1:14]
data_ggplot21 <- stack_search(tagged = c("ggplot2"), page = 2, pagesize = 20)[,1:14]
colnames(data_ggplot2)
colnames(data_ggplot21)
data_ggplot21 <- stack_search(tagged = c("ggplot2"), page = 5, pagesize = 20)[,1:14]
colnames(data_ggplot21)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 20, num_pages = 750)
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = 1, pagesize = 100, num_pages = 200)
colnames(data_ggplot2)
data_ggplot2[,c("tags", "title", "is_answered", "view_count", "answer_count", "score", "creation_date", "last_edit_date", "question_id", "link", "closed_date", "closed_reason")]
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 12))
for (i in 1:800) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)[,c("tags", "title", "is_answered", "view_count", "answer_count", "score", "creation_date", "last_edit_date", "question_id", "link", "closed_date", "closed_reason")]
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
} else {
break
}
}
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)
colnames(data_ggplot2)
dataset <- data.frame(matrix(NA, nrow = 0, ncol = 10))
for (i in 1:800) {
data_ggplot2 <- stack_search(tagged = c("ggplot2"), page = i, pagesize = 20)[,c("tags", "title", "is_answered", "view_count", "answer_count", "score", "creation_date", "last_edit_date", "question_id", "link")]
if (nrow(data_ggplot2) != 0) {
dataset <- rbind(dataset, data_ggplot2)
} else {
break
}
}
View(dataset)
write.csv(dataset, "stackoverflow_ggplot2.csv", row.names = F)
getTwitterOAuth("7ixJ3XU7zGRi95qI2H8muQ",
"IgqF4smkSwArxGcWdxx3QBJGgTp1X087p4rSkKZ6ikU")
setup_twitter_oauth("7ixJ3XU7zGRi95qI2H8muQ",
"IgqF4smkSwArxGcWdxx3QBJGgTp1X087p4rSkKZ6ikU")
setup_twitter_oauth("7ixJ3XU7zGRi95qI2H8muQ",
+                 "IgqF4smkSwArxGcWdxx3QBJGgTp1X087p4rSkKZ6ikU")
setup_twitter_oauth("7ixJ3XU7zGRi95qI2H8muQ", "IgqF4smkSwArxGcWdxx3QBJGgTp1X087p4rSkKZ6ikU")
searchTwitter('ggplot2',
n = 10000)
searchTwitter('ggplot2',
n = 10000) -> twitter_ggplot
?searchTwitter
searchTwitter('ggplot2',
n = 10000,
since = "2017/02/01") -> twitter_ggplot
searchTwitter('ggplot2',
since = "2017-02-01") -> twitter_ggplot
searchTwitter('ggplot2',
n = 10000) -> twitter_ggplot
searchTwitter('numpy',
n = 10000) -> twitter_ggplot
twitter_ggplot[1:10]
searchTwitter('numpy',
n = 10000,
since = "2017-02-01") -> twitter_ggplot
searchTwitter('numpy',
n = 10000,
since = "2017-02-09") -> twitter_ggplot
twitter_ggplot[1:20]
?retweetCount
?retweeted
twitter_ggplot.1 <- strip_retweets(twitter_ggplot)
twitter_ggplot.1[1:10]
twitter_ggplot.1[11:30]
searchTwitter('numpy',
n = 10000,
lang = "ENG",
since = "2017-02-09") -> twitter_ggplot
searchTwitter('numpy',
n = 10000,
lang = "eng",
since = "2017-02-09") -> twitter_ggplot
searchTwitter('numpy',
n = 10000,
lang = "en",
since = "2017-02-09") -> twitter_ggplot
twitter_ggplot.1 <- strip_retweets(twitter_ggplot)
twitter_ggplot.1[11:30]
twListToDF(twitter_ggplot)
data.frame <- twListToDF(twitter_ggplot.1)
write.csv(data.frame)
write.csv(data.frame, "twitter_numpy.csv", row.names = F)
View(data.frame)
citation()
knitr::opts_chunk$set(echo = TRUE)
data <- data.frame(A = c(0, 0.3, 0.4, 0.7),
B = c(0, 0, 0.5, 0.8),
C = c(0, 0, 0, 0.45),
D = c(rep(0, 4)))
distance <- as.dist(data)
plot(hclust(distance, method = "complete"))
plot(hclust(distance,
method = "complete",
main = "Hierarchical clustering - complete linking",
xlab = ""))
?plot
plot(hclust(distance,
method = "complete",
main = "Hierarchical clustering complete linking",
xlab = ""))
plot(hclust(distance,
method = "complete",
main = "Hierarchical clustering complete linking"))
plot(hclust(distance,
method = "complete"),
main = "Hierarchical clustering - complete linking",
xlab = ""))
plot(hclust(distance,
method = "complete"),
main = "Hierarchical clustering - complete linking",
xlab = "")
plot(hclust(distance,
method = "complete"),
main = "Hierarchical clustering - complete linking",
xlab = "", sub = "")
plot(hclust(distance,
method = "single"),
main = "Hierarchical clustering - complete linking",
xlab = "", sub = "")
plot(hclust(distance,
method = "complete"),
main = "Hierarchical clustering - complete linking",
xlab = "", sub = "")
plot(hclust(distance,
method = "single"),
main = "Hierarchical clustering - complete linking",
xlab = "", sub = "")
library(ISLR)
data <- USArrests
head(data)
nrow(data)
library(psych)
describe.by(data)
describeBy(data)
hist(data$Murder)
?par
par(mfrow = c(2,2))
hist(data$Murder)
hist(data$Assault)
hist(data$UrbanPop)
hist(data$Rape)
distance.2 <- as.dist(t(data))
distance.2 <- dist(as.matrix(t(data)))
distance.2
data
t(data)
as.matrix(t(data))
dist(as.matrix(t(data)))
as.dist(as.matrix(t(data)))
distance.2 <- dist(t(matrix(data)))
distance.2 <- as.dist(t(matrix(data)))
distance.2 <- as.dist(t(as.matrix(data)))
data
as.matrix(data)
t(as.matrix(data))
?as.dist
dist(data)
distance.2 <- as.dist(t(data))
distance.2 <- dist(t(data))
distance.2 <- dist(matrix(data))
distance.2 <- dist(as.matrix(data))
distance.2
distance.2 <- dist(data)
distance.2
plot(hclust(distance.2))
plot(hclust(distance.2,
method = "complete"))
?cutree
distance.2 <- dist(data)
fit <- hclust(distance.2,
method = "complete")
group <- cutree(fit, k = 3)
plot(fit)
rect.hclust(fit, k = 5)
distance.2 <- dist(data)
fit <- hclust(distance.2,
method = "complete")
plot(fit)
rect.hclust(fit, k = 3)
distance.2 <- dist(data)
fit <- hclust(distance.2,
method = "complete")
plot(fit)
rect.hclust(fit, k = 3)
distance.2 <- dist(data)
fit <- hclust(distance.2,
method = "complete")
plot(fit)
rect.hclust(fit, k = 3)
?hclust
data[,1:4] <- scale(data[,1:4])
data
?scale
distance.2 <- dist(data)
fit <- hclust(distance.2,
method = "complete")
plot(fit)
rect.hclust(fit, k = 3)
View(data)
data <- USArrests
describeBy(data)
par(mfrow = c(2,2))
hist(data$Murder)
hist(data$Assault)
hist(data$UrbanPop)
hist(data$Rape)
View(data)
data[,1:4] <- scale(data[,1:4])
distance.2 <- dist(data)
fit <- hclust(distance.2,
method = "complete")
plot(fit)
rect.hclust(fit, k = 3)
setwd("~/Documents/Github/PSY880_data_mining")
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(psych)
library(e1071)
library(pander)
library(tree)
library(rpart)
library(randomForest)
library(ggplot2)
data2016 <- read.csv("2016.csv")
colnames(data2016) <- c("FIPS", "State", "County", "Year", "Deaths", "smoker.percent", "obesity.percent", "drinking.percent", "uninsured.percent", "unemployed.percent", "food.insecure", "pm25", "water.violation", "health.food", "population", "deaths.previous")
data2016$water.violation <- ifelse(data2016$water.violation == "Yes", 1, 0)
for (i in 6:ncol(data2016)) {
for (j in 1:nrow(data2016)) {
if (is.na(data2016[j, i]) == T) {
data2016[j, i] <- mean(na.omit(data2016[,i]))
}
}
}
data2016 <- read.csv("2016.csv")
colnames(data2016) <- c("FIPS", "State", "County", "Year", "Deaths", "smoker.percent", "obesity.percent", "drinking.percent", "uninsured.percent", "unemployed.percent", "food.insecure", "pm25", "water.violation", "health.food", "population", "deaths.previous")
data2016$water.violation <- ifelse(data2016$water.violation == "Yes", 1, 0)
for (i in 6:ncol(data2016)) {
for (j in 1:nrow(data2016)) {
if (is.na(data2016[j, i]) == T) {
data2016[j, i] <- mean(na.omit(data2016[,i]))
}
}
}
rural <- read.csv("rural.csv")
data2016 <- merge(x = data2016, y = rural,
by.x = "FIPS",
by.y = "fips",
all.x = T,
all.y = F)
data2016$rurality.index <- ifelse(data2016$rurality < 50, "MU",
ifelse(data2016$rurality == 100, "AR", "MR"))
data2016 <- data2016[-which(is.na(data2016$Deaths) == T),]
data2016 <- data2016[-which(is.na(data2016$rurality) == T),]
data <- data2016[,c(6:14, 18)]
data$rurality.index <- as.factor(data$rurality.index)
# svm
set.seed(1)
train <- sample(nrow(data), 2000)
train.set <- as.data.frame(data[train,])
test.set <- as.data.frame(data[-train,])
summary_table <- read.csv("summary_table.csv")
pander(summary_table)
death.rate <- data2016$Deaths / data2016$population
data <- cbind(data, death.rate = death.rate)
data <- cbind(data, population = data2016$population)
train.set <- data[train,]
test.set <- data[-train,]
reg <- lm(death.rate ~ ., train.set)
summary(reg)
prediction.train <- predict(reg, train.set, type="response")
rmse.regression.train <- sqrt(mean((prediction.train - train.set$death.rate) ^ 2))
mae.regression.train <- mean(abs(prediction.train - train.set$death.rate))
prediction.test <- predict(reg, test.set, type = "response")
rmse.regression.test <- sqrt(mean((prediction.test - test.set$death.rate) ^ 2))
mae.regression.test <- mean(abs(prediction.test - test.set$death.rate))
# grow the tree
set.seed(1)
tree.train <- rpart(death.rate ~ .,
train.set,
method = "anova")
printcp(tree.train)
pruned.train <- prune.rpart(tree.train, cp = 0.010000)
plot(pruned.train)
text(pruned.train, pretty=0)
prediction.tree.train <- predict(pruned.train, train.set, type = "matrix")
rmse.tree.train <- sqrt(mean((prediction.tree.train - train.set$death.rate) ^ 2))
mae.tree.train <- mean(abs(prediction.tree.train - train.set$death.rate))
prediction.tree.test <- predict(pruned.train, test.set, type = "matrix")
rmse.tree.test <- sqrt(mean((prediction.tree.test - test.set$death.rate) ^ 2))
mae.tree.test <- mean(abs(prediction.tree.test - test.set$death.rate))
set.seed(1)
rf <- randomForest(death.rate ~ ., data = train.set, importance = T)
importance(rf)
prediction.rf.train <- predict(rf, train.set)
rmse.rf.train <- sqrt(mean((prediction.rf.train - train.set$death.rate) ^ 2))
mae.rf.train <- mean(abs(prediction.rf.train - train.set$death.rate))
prediction.rf.test <- predict(rf, test.set)
rmse.rf.test <- sqrt(mean((prediction.rf.test - test.set$death.rate) ^ 2))
mae.rf.test <- mean(abs(prediction.rf.test - test.set$death.rate))
# quantilize the population
quantile <- ecdf(data2016$population)
for (i in 1:nrow(train.set)) {
train.set$value[i] <- quantile(train.set$population[i])
train.set$quantile[i] <- ifelse(train.set$value[i] < .25, "1",
ifelse(train.set$value[i] < .5, "2",
ifelse(train.set$value[i] < .75, "3", "4")))
}
difference <- data.frame(quantile = as.numeric(train.set$quantile),
real.death.rate = as.numeric(train.set$death.rate),
predict.death.rate = as.numeric(prediction.rf.train))
plot <- ggplot(difference, aes(x = real.death.rate, y = predict.death.rate)) +
geom_point() +
lims(x = c(0, 0.025), y = c(0, 0.025)) +
geom_abline() +
facet_wrap(~ quantile)
plot
difference$gap <- difference$real.death.rate - difference$predict.death.rate
plot(difference$gap ~ as.factor(difference$quantile))
View(difference)
anova.train <- anova(gap ~ quantile, data = difference)
anova.train <- ls(gap ~ quantile, data = difference)
anova.train <- aov(gap ~ quantile, data = difference)
summary(anova.train)
TukeyHSD(anova.train)
difference$quantile <- as.factor(difference$quantile)
anova.train <- aov(gap ~ quantile, data = difference)
summary(anova.train)
TukeyHSD(anova.train)
difference$quantile <- as.factor(difference$quantile)
anova.train <- aov(gap ~ quantile, data = difference)
summary(anova.train)
TukeyHSD(anova.train)
quantile <- ecdf(data2016$population)
for (i in 1:nrow(test.set)) {
test.set$value[i] <- quantile(test.set$population[i])
test.set$quantile[i] <- ifelse(test.set$value[i] < .25, "1",
ifelse(test.set$value[i] < .5, "2",
ifelse(test.set$value[i] < .75, "3", "4")))
}
difference <- data.frame(quantile = as.numeric(test.set$quantile),
real.death.rate = as.numeric(test.set$death.rate),
predict.death.rate = as.numeric(prediction.rf.test))
plot <- ggplot(difference, aes(x = real.death.rate, y = predict.death.rate)) +
geom_point() +
lims(x = c(0, 0.025), y = c(0, 0.025)) +
geom_abline() +
facet_wrap(~ quantile)
plot
difference$gap <- difference$real.death.rate - difference$predict.death.rate
plot(difference$gap ~ as.factor(difference$quantile))
## Difference could be determined by ANOVA.
difference$quantile <- as.factor(difference$quantile)
anova.train <- aov(gap ~ quantile, data = difference)
summary(anova.train)
TukeyHSD(anova.train)
quantile <- ecdf(data2016$population)
for (i in 1:nrow(train.set)) {
train.set$value[i] <- quantile(train.set$population[i])
train.set$quantile[i] <- ifelse(train.set$value[i] < .25, "1",
ifelse(train.set$value[i] < .5, "2",
ifelse(train.set$value[i] < .75, "3", "4")))
}
difference <- data.frame(quantile = as.numeric(train.set$quantile),
real.death.rate = as.numeric(train.set$death.rate),
predict.death.rate = as.numeric(prediction.rf.train))
plot <- ggplot(difference, aes(x = real.death.rate, y = predict.death.rate)) +
geom_point() +
lims(x = c(0, 0.025), y = c(0, 0.025)) +
geom_abline() +
facet_wrap(~ quantile)
plot
difference$gap <- difference$real.death.rate - difference$predict.death.rate
plot(difference$gap ~ as.factor(difference$quantile))
difference$quantile <- as.factor(difference$quantile)
difference$gap.1 <- abs(difference$gap)
anova.train <- aov(gap.1 ~ quantile, data = difference)
summary(anova.train)
TukeyHSD(anova.train)
quantile <- ecdf(data2016$population)
for (i in 1:nrow(test.set)) {
test.set$value[i] <- quantile(test.set$population[i])
test.set$quantile[i] <- ifelse(test.set$value[i] < .25, "1",
ifelse(test.set$value[i] < .5, "2",
ifelse(test.set$value[i] < .75, "3", "4")))
}
difference <- data.frame(quantile = as.numeric(test.set$quantile),
real.death.rate = as.numeric(test.set$death.rate),
predict.death.rate = as.numeric(prediction.rf.test))
plot <- ggplot(difference, aes(x = real.death.rate, y = predict.death.rate)) +
geom_point() +
lims(x = c(0, 0.025), y = c(0, 0.025)) +
geom_abline() +
facet_wrap(~ quantile)
plot
difference$gap <- difference$real.death.rate - difference$predict.death.rate
plot(difference$gap ~ as.factor(difference$quantile))
## Difference could be determined by ANOVA.
difference$gap.1 <- abs(difference$gap)
difference$quantile <- as.factor(difference$quantile)
anova.train <- aov(gap.1 ~ quantile, data = difference)
summary(anova.train)
TukeyHSD(anova.train)
